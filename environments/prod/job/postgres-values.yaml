global:
  security:
    allowInsecureImages: true
auth:
  username: svcuser
  existingSecret: job-db-secrets
  secretKeys:
    adminPasswordKey: admin-password
    userPasswordKey: password
image:
  repository: "postgres"
  tag: "1.2.0"
serviceAccount:
  name: job-sa
  create: false
readReplicas:
  replicaCount: 0
primary:
  extendedConfiguration: |
    max_connections = 300
    shared_buffers = 256MB
    work_mem = 2MB
    maintenance_work_mem = 64MB
    effective_cache_size = 1GB
    wal_buffers = 4MB
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "1Gi"
      cpu: "1"
  containerSecurityContext:
    readOnlyRootFilesystem: false
  persistence:
    enabled: true
    size: 50Gi
    storageClass: block-general
    accessModes: 
      - ReadWriteOnce
  service:
    ports:
      postgresql: 5432
  extraVolumes:
    - name: job-secrets-store
      csi:
        driver: secrets-store.csi.k8s.io
        readOnly: true
        volumeAttributes:
          secretProviderClass: "job-db-secrets"
  initdb:
    user: svcuser
    scripts:
      init.sql: |
        CREATE DATABASE job;
        GRANT ALL PRIVILEGES ON DATABASE job TO svcuser;

        \c job;

        CREATE SCHEMA core;

        DROP TABLE IF EXISTS core.events CASCADE;
        DROP TABLE IF EXISTS core.entities CASCADE;
        DROP TABLE IF EXISTS core.snapshots CASCADE;
        DROP TABLE IF EXISTS core.cdc_monitoring CASCADE;

        CREATE TABLE core.events (
          event_id VARCHAR(1000) PRIMARY KEY,
          event_type VARCHAR(1000),
          event_data VARCHAR(1000) NOT NULL,
          entity_type VARCHAR(1000) NOT NULL,
          entity_id VARCHAR(1000) NOT NULL,
          triggering_event VARCHAR(1000),
          metadata VARCHAR(1000),
          published SMALLINT DEFAULT 0
        );

        CREATE INDEX events_idx ON core.events(entity_type, entity_id, event_id);
        CREATE INDEX events_published_idx ON core.events(published, event_id);

        CREATE TABLE core.entities (
          entity_type VARCHAR(1000),
          entity_id VARCHAR(1000),
          entity_version VARCHAR(1000) NOT NULL,
          PRIMARY KEY(entity_type, entity_id)
        );

        CREATE INDEX entities_idx ON core.entities(entity_type, entity_id);

        CREATE TABLE core.snapshots (
          entity_type VARCHAR(1000),
          entity_id VARCHAR(1000),
          entity_version VARCHAR(1000),
          snapshot_type VARCHAR(1000) NOT NULL,
          snapshot_json VARCHAR(1000) NOT NULL,
          triggering_events VARCHAR(1000),
          PRIMARY KEY(entity_type, entity_id, entity_version)
        );

        CREATE TABLE core.cdc_monitoring (
          reader_id VARCHAR(1000) PRIMARY KEY,
          last_time BIGINT
        );

        DROP TABLE IF EXISTS core.message CASCADE;
        DROP TABLE IF EXISTS core.received_messages CASCADE;

        CREATE TABLE core.message (
          id VARCHAR(1000) PRIMARY KEY,
          destination TEXT NOT NULL,
          headers TEXT NOT NULL,
          payload TEXT NOT NULL,
          published SMALLINT DEFAULT 0,
          message_partition SMALLINT,
          creation_time BIGINT
        );

        CREATE INDEX message_published_idx ON core.message(published, id);

        CREATE TABLE core.received_messages (
          consumer_id VARCHAR(1000),
          message_id VARCHAR(1000),
          creation_time BIGINT,
          published SMALLINT DEFAULT 0,
          PRIMARY KEY(consumer_id, message_id)
        );

        CREATE TABLE core.offset_store(
          client_name VARCHAR(255) NOT NULL PRIMARY KEY,
          serialized_offset VARCHAR(255)
        );

        SELECT * FROM pg_create_logical_replication_slot('core_slot', 'wal2json');
        SELECT * FROM pg_create_logical_replication_slot('core_slot2', 'wal2json');

        ALTER TABLE core.message DROP COLUMN payload;
        ALTER TABLE core.message ADD COLUMN payload JSON;

        ALTER TABLE core.message DROP COLUMN headers;
        ALTER TABLE core.message ADD COLUMN headers JSON;

        DROP Table IF Exists core.saga_instance_participants;
        DROP Table IF Exists core.saga_instance;
        DROP Table IF Exists core.saga_lock_table;
        DROP Table IF Exists core.saga_stash_table;

        CREATE TABLE core.saga_instance_participants (
          saga_type VARCHAR(512) NOT NULL,
          saga_id VARCHAR(100) NOT NULL,
          destination VARCHAR(512) NOT NULL,
          resource VARCHAR(512) NOT NULL,
          PRIMARY KEY(saga_type, saga_id, destination, resource)
        );

        CREATE TABLE core.saga_instance(
          saga_type VARCHAR(512) NOT NULL,
          saga_id VARCHAR(100) NOT NULL,
          state_name VARCHAR(100) NOT NULL,
          last_request_id VARCHAR(100),
          end_state BOOLEAN,
          compensating BOOLEAN,
          failed BOOLEAN,
          saga_data_type VARCHAR(1024) NOT NULL,
          saga_data_json TEXT NOT NULL,
          PRIMARY KEY(saga_type, saga_id)
        );

        create table core.saga_lock_table(
          target VARCHAR(512) PRIMARY KEY,
          saga_type VARCHAR(512) NOT NULL,
          saga_Id VARCHAR(100) NOT NULL
        );

        create table core.saga_stash_table(
          message_id VARCHAR(100) PRIMARY KEY,
          target VARCHAR(512) NOT NULL,
          saga_type VARCHAR(512) NOT NULL,
          saga_id VARCHAR(100) NOT NULL,
          message_headers TEXT NOT NULL,
          message_payload TEXT NOT NULL
          );
  extraVolumeMounts:
    - name: job-secrets-store
      mountPath: "/mnt/secrets-store"
      readOnly: true
  pgHbaConfiguration: |-
    host all svcuser 0.0.0.0/0 trust
    local all postgres trust
    local all svcuser  trust